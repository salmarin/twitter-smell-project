{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stripe bat be hang on their foot for good'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "nlp_ner = spacy.load('en_core_web_sm', disable=['parser'])\n",
    "\n",
    "'''sentence = \"The striped bats are hanging on their feet for best\"\n",
    "\n",
    "# Parse the sentence using the loaded 'en' model object `nlp`\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Extract the lemma for each token and join\n",
    "\" \".join([token.lemma_ for token in doc])\n",
    "#> 'the strip bat be hang on -PRON- foot for good''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('model_2_results_positive_from30000samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    smell_words=[\"Stink\",\"Scent\",\"Smell\",\"Odour\",\"Odor\",\"Stench\",\"Reek\",\"Aroma\",\"Aromatic\",\"Whiff\",\"Foetor\",\"Fetor\",\"Fragrance\",\"Musk\",\"Rankness\",\"Redolence\",\"Pong\",\"Pungency\",\"Niff\",\"Deodorant\",\"Essence\",\"Atmosphere\",\"Olfaction\",\n",
    "                               \"Stinking\",\"Stank\",\"Stunk\",\"Scented\",\"Odourless\",\"Odoriferous\",\"Odorous\",\"Malodorous\",\"Reeking\",\"Aromatic\",\"Whiffy\",\"Fetid\",\"Foetid\",\"Fragrant\",\"Fragranced\",\"Redolent\",\"Frowzy\",\"Frowsy\",\"Pungent\",\"Funky\",\"Musty\",\"Niffy\",\"Unscented\",\"Scentless\",\"Deodorized\",\"Noisome\",\"Smelly\",\"Mepehitic\",\"Muddle\",\"Putrid\",\"Olfactory\",\"Musky\",\"Pungently\",\n",
    "                               \"Smelling\",\"Smelled\",\"Reeked\",\"Sniff\",\"Sniffed\",\"Sniffing\",\"Whiffed\",\"Deodorized\",\"Deodorizing\",\"Snuffing\",\"Snuffed\"]\n",
    "    smell_words_lower=[x.lower() for x in smell_words]\n",
    "\n",
    "    my_words=['love', 'good', 'new','stink', 'stank',\"n't\", 'ca', \"'s\", \"gon\", 'na', 'll', 't', 'ur', 'bc', 'nt', 'yo', 've', 'ai','lol','cause']\n",
    "\n",
    "    # stop = stopwords.words('english')\n",
    "    s= set(ENGLISH_STOP_WORDS).union(smell_words).union(my_words).union(smell_words_lower) #.union(set(stop))\n",
    "    \n",
    "    #taking off links\n",
    "    df['Text']=df['sentence'].apply(lambda x: re.split('http*:\\/\\/.*', str(x))[0])\n",
    "\n",
    "    # make everything lower case, Not done for proper nouns\n",
    "    # df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "    #take off stop words\n",
    "    df['Text_clean'] = df['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (s)]))\n",
    "    \n",
    "    # only take a lsit of clean texts, since that is what the moel needs as input : a list\n",
    "    docs = list(df['Text_clean'].loc[:].values)\n",
    "    \n",
    "    # lemmatization\n",
    "    \n",
    "    '''nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    \n",
    "    lem_token= [nlp(sentence) for sentence in docs] \n",
    "    lem_doc= [\" \".join([token.lemma_ for token in tok]) for tok in lem_token]\n",
    "    clean_lem = [' '.join([word for word in row.split() if word not in (s)]) for row in lem_doc]\n",
    "    \n",
    "    clean_lem[:5]'''\n",
    "    return docs\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc=preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19474"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function str.index>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc[:5][0].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "docu = [[nlp_ner(sentence),sentence] for sentence in dfc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entities=pd.DataFrame([], columns=['text','label','explanation'])\n",
    "\n",
    "for sentence in docu:\n",
    "    for word in sentence[0].ents:\n",
    "        entities = entities.append({\n",
    "            'sentence': sentence[1],\n",
    "            'text': word.text,\n",
    "            'label': word.label_,\n",
    "            'explanation': spacy.explain(word.label_)\n",
    "        }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tomorrow</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Absolute or relative dates or periods</td>\n",
       "      <td>Tomorrow @ 12 EST! Hsuan's book aesthetics inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hsuan</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>People, including fictional</td>\n",
       "      <td>Tomorrow @ 12 EST! Hsuan's book aesthetics inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Organic Rose Water Organic Aloe Vera Gel</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Companies, agencies, institutions, etc.</td>\n",
       "      <td>Hydrate Toner moisturizing ingredients like Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mandalay</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>Monetary values, including unit</td>\n",
       "      <td>Soon residents downtown #Mandalay lit candles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#militarycoup</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>Monetary values, including unit</td>\n",
       "      <td>Soon residents downtown #Mandalay lit candles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Myanmar</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Countries, cities, states</td>\n",
       "      <td>Soon residents downtown #Mandalay lit candles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>Numerals that do not fall under another type</td>\n",
       "      <td>Soon residents downtown #Mandalay lit candles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>today</td>\n",
       "      <td>DATE</td>\n",
       "      <td>Absolute or relative dates or periods</td>\n",
       "      <td>Can sell set today? Lime, mandarin basil wax m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TB</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Companies, agencies, institutions, etc.</td>\n",
       "      <td>Can sell set today? Lime, mandarin basil wax m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p*ssy p*ssy loyal</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>Monetary values, including unit</td>\n",
       "      <td>pray dirty house educated hoe job gold digger ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text     label  \\\n",
       "0                                  Tomorrow      DATE   \n",
       "1                                     Hsuan    PERSON   \n",
       "2  Organic Rose Water Organic Aloe Vera Gel       ORG   \n",
       "3                                  Mandalay     MONEY   \n",
       "4                             #militarycoup     MONEY   \n",
       "5                                   Myanmar       GPE   \n",
       "6                                         #  CARDINAL   \n",
       "7                                     today      DATE   \n",
       "8                                        TB       ORG   \n",
       "9                         p*ssy p*ssy loyal     MONEY   \n",
       "\n",
       "                                    explanation  \\\n",
       "0         Absolute or relative dates or periods   \n",
       "1                   People, including fictional   \n",
       "2       Companies, agencies, institutions, etc.   \n",
       "3               Monetary values, including unit   \n",
       "4               Monetary values, including unit   \n",
       "5                     Countries, cities, states   \n",
       "6  Numerals that do not fall under another type   \n",
       "7         Absolute or relative dates or periods   \n",
       "8       Companies, agencies, institutions, etc.   \n",
       "9               Monetary values, including unit   \n",
       "\n",
       "                                            sentence  \n",
       "0  Tomorrow @ 12 EST! Hsuan's book aesthetics inc...  \n",
       "1  Tomorrow @ 12 EST! Hsuan's book aesthetics inc...  \n",
       "2  Hydrate Toner moisturizing ingredients like Or...  \n",
       "3  Soon residents downtown #Mandalay lit candles ...  \n",
       "4  Soon residents downtown #Mandalay lit candles ...  \n",
       "5  Soon residents downtown #Mandalay lit candles ...  \n",
       "6  Soon residents downtown #Mandalay lit candles ...  \n",
       "7  Can sell set today? Lime, mandarin basil wax m...  \n",
       "8  Can sell set today? Lime, mandarin basil wax m...  \n",
       "9  pray dirty house educated hoe job gold digger ...  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuecounts= entities[entities.label == 'GPE']['text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "⠀           174\n",
       "US           37\n",
       "UK           20\n",
       "Texas        16\n",
       "Miami        16\n",
       "China        16\n",
       "Ireland      14\n",
       "DC           14\n",
       "Scotland     14\n",
       "America      14\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valuecounts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2420                                                Texas friends, care mentally week. Today’s announcement absolute hot, garbage feel little hopeless today. Take break, don’t doom scroll, let breathe little.\n",
       "2561                          House member Rep Roy Texas today’s hearing hate speech crimes bragging 700 lynchings TX did people color. A tall tree idea cool. This racist go. You help ALL people district hate\n",
       "3034     Rep. Ronny Jackson, R-Texas, sexual denigrating statements female subordinate, alcohol duty, humiliated staff long stint White House physician, scathing inspector general report finds. https://kpb...\n",
       "4556                        Tasty Texas wine pair w spicy prawn n chorizo jambalaya! @mcphersoncellar Tri Colore Red treat - medium-dry, dark grapes & nicely rugged texture-yum! #texaswine #winesndfoodpairing\n",
       "7047                                                                                I things JFK dad called said got tickets 6th Floor Museum Saturday. We plans visit Texas Theatre Oswald's grave. I'm excited\n",
       "10623                                                                                                                                                                                    It 11:15 Texas already.\n",
       "13139                                                                                                                                                 Elon Plans New City Texas - Called Starbase Led 'The Doge'\n",
       "15367                                                                                          Idk y'all, depression came force news Texas opening hit. My hope really riding vaccines, singlehandedly hope out.\n",
       "17061                                                                                                                                               Texas. Baby. I’m sorry. What nasty, terrifying situation in.\n",
       "17545    Aguiluchos en el #SpringTraining Miguel Yajure (Piratas) 2.0 IP, 2 K. (3.00) Rougned 3B ( Texas) 2-1, K. (364) Ronald Torreyes SS (Phillies) 2-0 Adrián Sánchez 3B (Nacionales) 1-0 #MLB #Águilas #A...\n",
       "17672                             Texas lifted mask mandate I’m vaccinated yet, I’m worried, immune notch, battle tested. I’ve eaten ass hipster Montrose girls don’t believe I met open mic. I’m indestructible\n",
       "18047                                                                                                                    Way Texas!!! America alive Southern states! We're heading way...the Shitcago unbearable\n",
       "19507                                                                                                                                           Dog: \"What HAIL stuff I'm sniffing??\" (It hail. It hailed Texas)\n",
       "20913                                                                                                                                                         Pull Texas southern basketball, pull football team\n",
       "20989    “stench public marijuana” #JimCrow @WhiteHouse #Cannabis 550 nutrients God says “eat meat” #Capitalism #Socialism #Oligarchs @GOP @DNC = @NYSE Water, Food, Housing, #Texas lost crops ~ Plant, grow...\n",
       "21761                                                                                                                                                           I'm going fly Texas weekend just I freedom 48hrs\n",
       "Name: sentence, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context(\"display.min_rows\", 50, \"display.max_rows\", 200, \"display.max_columns\", 15, 'display.max_colwidth', 200):\n",
    "    display(entities[entities.text == 'Texas']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
